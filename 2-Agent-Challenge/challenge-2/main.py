"""
Challenge 2: æ¡ä»¶è·¯ç”±å’Œå·¥å…·è°ƒç”¨

å­¦ä¹ ç›®æ ‡:
- æŒæ¡æ¡ä»¶è¾¹(Conditional Edges)çš„ä½¿ç”¨
- å­¦ä¹ åŠ¨æ€è·¯ç”±å†³ç­–
- å®ç°å·¥å…·é›†æˆå’Œè°ƒç”¨
- å¤„ç†é”™è¯¯å’Œé‡è¯•æœºåˆ¶

æ ¸å¿ƒæ¦‚å¿µ:
1. add_conditional_edges() - æ¡ä»¶è¾¹æ·»åŠ 
2. è·¯ç”±å‡½æ•°è®¾è®¡ - åŠ¨æ€å†³ç­–é€»è¾‘
3. å·¥å…·ç»‘å®šå’Œè°ƒç”¨ - å‡½æ•°å·¥å…·é›†æˆ
4. çŠ¶æ€æ›´æ–°ç­–ç•¥ - ç»“æœå¤„ç†å’ŒçŠ¶æ€ç®¡ç†
"""

import os
import json
import requests
from datetime import datetime
from typing import TypedDict, Annotated, Literal
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool

# æ£€æŸ¥ç¯å¢ƒå˜é‡
if not os.getenv("OPENAI_API_KEY"):
    print("âš ï¸  è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    exit(1)

# 1. å®šä¹‰çŠ¶æ€ç»“æ„
class AgentState(TypedDict):
    """æ™ºèƒ½åŠ©æ‰‹çš„çŠ¶æ€å®šä¹‰"""
    messages: Annotated[list, add_messages]
    user_intent: str  # ç”¨æˆ·æ„å›¾: search, calculate, translate, weather, chat
    tool_calls_count: int  # å·¥å…·è°ƒç”¨æ¬¡æ•°
    last_tool_result: str  # æœ€åçš„å·¥å…·è°ƒç”¨ç»“æœ

# 2. å®šä¹‰å·¥å…·å‡½æ•°
@tool
def calculator(expression: str) -> str:
    """æ‰§è¡Œæ•°å­¦è®¡ç®—
    
    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ "2+3*4"
    
    Returns:
        è®¡ç®—ç»“æœ
    """
    try:
        # å®‰å…¨çš„æ•°å­¦è®¡ç®—
        allowed_chars = set('0123456789+-*/()., ')
        if not all(c in allowed_chars for c in expression):
            return "é”™è¯¯ï¼šè¡¨è¾¾å¼åŒ…å«ä¸å…è®¸çš„å­—ç¬¦"
        
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"

@tool  
def translator(text: str, target_language: str = "è‹±æ–‡") -> str:
    """ç¿»è¯‘æ–‡æœ¬
    
    Args:
        text: è¦ç¿»è¯‘çš„æ–‡æœ¬
        target_language: ç›®æ ‡è¯­è¨€ï¼Œé»˜è®¤ä¸ºè‹±æ–‡
        
    Returns:
        ç¿»è¯‘ç»“æœ
    """
    # æ¨¡æ‹Ÿç¿»è¯‘åŠŸèƒ½
    translations = {
        "è‹±æ–‡": {
            "ä½ å¥½": "Hello",
            "å†è§": "Goodbye", 
            "è°¢è°¢": "Thank you",
            "æ—©ä¸Šå¥½": "Good morning"
        },
        "ä¸­æ–‡": {
            "hello": "ä½ å¥½",
            "goodbye": "å†è§",
            "thank you": "è°¢è°¢",
            "good morning": "æ—©ä¸Šå¥½"
        }
    }
    
    text_lower = text.lower()
    if target_language in translations and text_lower in translations[target_language]:
        result = translations[target_language][text_lower]
        return f"ç¿»è¯‘ç»“æœ: {text} â†’ {result} ({target_language})"
    else:
        return f"æ¨¡æ‹Ÿç¿»è¯‘: '{text}' ç¿»è¯‘ä¸º{target_language}"

@tool
def web_search(query: str) -> str:
    """æ¨¡æ‹Ÿç½‘ç»œæœç´¢
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        
    Returns:
        æœç´¢ç»“æœæ‘˜è¦
    """
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    mock_results = {
        "python": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºWebå¼€å‘ã€æ•°æ®ç§‘å­¦ã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚",
        "ai": "äººå·¥æ™ºèƒ½(AI)æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚",
        "langgraph": "LangGraphæ˜¯LangChainçš„ä¸€ä¸ªæ‰©å±•ï¼Œç”¨äºæ„å»ºæœ‰çŠ¶æ€çš„ã€å¤šæ­¥éª¤çš„AIåº”ç”¨ç¨‹åºã€‚"
    }
    
    query_lower = query.lower()
    for key, value in mock_results.items():
        if key in query_lower:
            return f"æœç´¢ç»“æœ: {value}"
    
    return f"æ¨¡æ‹Ÿæœç´¢: å…³äº'{query}'çš„ç›¸å…³ä¿¡æ¯..."

@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´
    
    Returns:
        å½“å‰æ—¥æœŸå’Œæ—¶é—´
    """
    now = datetime.now()
    return f"å½“å‰æ—¶é—´: {now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}"

# 3. åˆå§‹åŒ–LLMå’Œå·¥å…·
tools = [calculator, translator, web_search, get_current_time]
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)
llm_with_tools = llm.bind_tools(tools)

# 4. æ„å›¾è¯†åˆ«å‡½æ•°
def analyze_intent(user_input: str) -> str:
    """åˆ†æç”¨æˆ·æ„å›¾"""
    user_input_lower = user_input.lower()
    
    # è®¡ç®—æ„å›¾
    if any(word in user_input_lower for word in ["è®¡ç®—", "ç®—", "+", "-", "*", "/", "ç­‰äº"]):
        return "calculate"
    
    # ç¿»è¯‘æ„å›¾  
    if any(word in user_input_lower for word in ["ç¿»è¯‘", "translate", "è‹±æ–‡", "ä¸­æ–‡"]):
        return "translate"
    
    # æœç´¢æ„å›¾
    if any(word in user_input_lower for word in ["æœç´¢", "æŸ¥æ‰¾", "æœ", "ä»€ä¹ˆæ˜¯", "ä»‹ç»"]):
        return "search"
    
    # æ—¶é—´æ„å›¾
    if any(word in user_input_lower for word in ["æ—¶é—´", "ç°åœ¨", "å‡ ç‚¹", "æ—¥æœŸ"]):
        return "time"
    
    # é»˜è®¤èŠå¤©æ„å›¾
    return "chat"

# 5. èŠ‚ç‚¹å‡½æ•°å®šä¹‰
def intent_analysis_node(state: AgentState) -> dict:
    """æ„å›¾åˆ†æèŠ‚ç‚¹"""
    print("ğŸ§  [æ„å›¾åˆ†æ] åˆ†æç”¨æˆ·æ„å›¾...")
    
    last_message = state["messages"][-1]
    user_input = last_message.content
    
    intent = analyze_intent(user_input)
    print(f"   è¯†åˆ«æ„å›¾: {intent}")
    
    return {
        "user_intent": intent,
        "tool_calls_count": state.get("tool_calls_count", 0)
    }

def tool_calling_node(state: AgentState) -> dict:
    """å·¥å…·è°ƒç”¨èŠ‚ç‚¹"""
    print("ğŸ”§ [å·¥å…·è°ƒç”¨] ä½¿ç”¨å·¥å…·å¤„ç†è¯·æ±‚...")
    
    # è°ƒç”¨LLMæ¥å†³å®šä½¿ç”¨å“ªä¸ªå·¥å…·
    response = llm_with_tools.invoke(state["messages"])
    
    tool_calls_count = state.get("tool_calls_count", 0) + 1
    
    # å¦‚æœLLMå†³å®šè°ƒç”¨å·¥å…·
    if response.tool_calls:
        tool_result = ""
        messages_to_add = [response]
        
        for tool_call in response.tool_calls:
            print(f"   è°ƒç”¨å·¥å…·: {tool_call['name']}")
            print(f"   å‚æ•°: {tool_call['args']}")
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            tool_name = tool_call["name"]
            tool_args = tool_call["args"]
            
            # æ‰¾åˆ°å¯¹åº”çš„å·¥å…·å¹¶æ‰§è¡Œ
            for tool in tools:
                if tool.name == tool_name:
                    result = tool.invoke(tool_args)
                    tool_result = result
                    
                    # æ·»åŠ å·¥å…·æ¶ˆæ¯
                    messages_to_add.append(
                        ToolMessage(
                            content=result,
                            tool_call_id=tool_call["id"]
                        )
                    )
                    break
        
        return {
            "messages": messages_to_add,
            "tool_calls_count": tool_calls_count,
            "last_tool_result": tool_result
        }
    else:
        return {
            "messages": [response],
            "tool_calls_count": tool_calls_count,
            "last_tool_result": "æœªä½¿ç”¨å·¥å…·"
        }

def chat_node(state: AgentState) -> dict:
    """æ™®é€šèŠå¤©èŠ‚ç‚¹"""
    print("ğŸ’¬ [èŠå¤©] ç”Ÿæˆå¯¹è¯å›å¤...")
    
    # æ„å»ºä¸Šä¸‹æ–‡
    context = f"""ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚
å½“å‰å¯¹è¯è½®æ•°: {state.get('tool_calls_count', 0)}
æœ€è¿‘å·¥å…·ç»“æœ: {state.get('last_tool_result', 'æ— ')}

è¯·ç”Ÿæˆè‡ªç„¶ã€æœ‰å¸®åŠ©çš„å›å¤ã€‚"""
    
    messages = [
        {"role": "system", "content": context}
    ] + [
        {"role": "human" if isinstance(msg, HumanMessage) else "assistant", 
         "content": msg.content}
        for msg in state["messages"]
        if not isinstance(msg, ToolMessage)  # è¿‡æ»¤å·¥å…·æ¶ˆæ¯
    ]
    
    response = llm.invoke(messages)
    
    return {
        "messages": [AIMessage(content=response.content)],
        "tool_calls_count": state.get("tool_calls_count", 0) + 1
    }

def final_response_node(state: AgentState) -> dict:
    """æœ€ç»ˆå›å¤æ•´åˆèŠ‚ç‚¹"""
    print("âœ¨ [æœ€ç»ˆå›å¤] æ•´åˆå·¥å…·ç»“æœ...")
    
    # å¦‚æœæœ‰å·¥å…·ç»“æœï¼Œç”ŸæˆåŒ…å«å·¥å…·ç»“æœçš„å›å¤
    if state.get("last_tool_result") and state.get("last_tool_result") != "æœªä½¿ç”¨å·¥å…·":
        prompt = f"""æ ¹æ®å·¥å…·æ‰§è¡Œç»“æœï¼Œç”Ÿæˆä¸€ä¸ªè‡ªç„¶çš„å›å¤ç»™ç”¨æˆ·ã€‚

å·¥å…·ç»“æœ: {state['last_tool_result']}
å¯¹è¯å†å²: {[msg.content for msg in state['messages'] if isinstance(msg, (HumanMessage, AIMessage))]}

è¯·ç”Ÿæˆä¸€ä¸ªå‹å¥½ã€æœ‰å¸®åŠ©çš„å›å¤ï¼Œè‡ªç„¶åœ°æ•´åˆå·¥å…·ç»“æœã€‚"""
        
        response = llm.invoke([{"role": "user", "content": prompt}])
        
        return {
            "messages": [AIMessage(content=response.content)]
        }
    else:
        # æ²¡æœ‰å·¥å…·ç»“æœï¼Œç›´æ¥è¿”å›æœ€åçš„AIæ¶ˆæ¯
        return {}

# 6. è·¯ç”±å‡½æ•°
def route_by_intent(state: AgentState) -> Literal["tool_calling", "chat"]:
    """æ ¹æ®æ„å›¾è·¯ç”±åˆ°ä¸åŒèŠ‚ç‚¹"""
    intent = state.get("user_intent", "chat")
    
    if intent in ["calculate", "translate", "search", "time"]:
        return "tool_calling"
    else:
        return "chat"

def should_use_final_response(state: AgentState) -> Literal["final_response", "end"]:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦æœ€ç»ˆå›å¤èŠ‚ç‚¹"""
    if state.get("last_tool_result") and state.get("last_tool_result") != "æœªä½¿ç”¨å·¥å…·":
        return "final_response"
    else:
        return "end"

# 7. æ„å»ºçŠ¶æ€å›¾
def create_smart_assistant():
    """åˆ›å»ºæ™ºèƒ½åŠ©æ‰‹"""
    
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("intent_analysis", intent_analysis_node)
    workflow.add_node("tool_calling", tool_calling_node)
    workflow.add_node("chat", chat_node)
    workflow.add_node("final_response", final_response_node)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.add_edge(START, "intent_analysis")
    
    # æ ¹æ®æ„å›¾è·¯ç”±
    workflow.add_conditional_edges(
        "intent_analysis",
        route_by_intent,
        {
            "tool_calling": "tool_calling",
            "chat": "chat"
        }
    )
    
    # å·¥å…·è°ƒç”¨åçš„è·¯ç”±
    workflow.add_conditional_edges(
        "tool_calling",
        should_use_final_response,
        {
            "final_response": "final_response", 
            "end": END
        }
    )
    
    # èŠå¤©å’Œæœ€ç»ˆå›å¤éƒ½ç»“æŸ
    workflow.add_edge("chat", END)
    workflow.add_edge("final_response", END)
    
    return workflow.compile()

# 8. äº¤äº’å¼æ¼”ç¤º
def run_smart_assistant():
    """è¿è¡Œæ™ºèƒ½åŠ©æ‰‹æ¼”ç¤º"""
    print("=" * 60)
    print("ğŸ¤– Challenge 2: æ¡ä»¶è·¯ç”±å’Œå·¥å…·è°ƒç”¨æ™ºèƒ½åŠ©æ‰‹")
    print("=" * 60)
    print("åŠŸèƒ½æ¼”ç¤º:")
    print("ğŸ§® è®¡ç®—: 'è®¡ç®— 2+3*4'")
    print("ğŸŒ ç¿»è¯‘: 'ç¿»è¯‘ hello ä¸ºä¸­æ–‡'")
    print("ğŸ” æœç´¢: 'æœç´¢ Python ç¼–ç¨‹'")
    print("ğŸ• æ—¶é—´: 'ç°åœ¨å‡ ç‚¹äº†'")
    print("ğŸ’¬ èŠå¤©: 'ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·'")
    print("\nè¾“å…¥ 'quit' é€€å‡º")
    print("-" * 60)
    
    assistant = create_smart_assistant()
    
    while True:
        user_input = input("\nğŸ‘¤ ä½ : ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'q']:
            print("ğŸ‘‹ å†è§!")
            break
            
        if not user_input:
            continue
            
        try:
            # æ„å»ºåˆå§‹çŠ¶æ€
            initial_state = {
                "messages": [HumanMessage(content=user_input)],
                "user_intent": "",
                "tool_calls_count": 0,
                "last_tool_result": ""
            }
            
            print(f"\nğŸ”„ å¤„ç†è¯·æ±‚: {user_input}")
            print("-" * 40)
            
            # æ‰§è¡Œå·¥ä½œæµ
            result = assistant.invoke(initial_state)
            
            # è·å–æœ€ç»ˆå›å¤
            ai_messages = [msg for msg in result["messages"] if isinstance(msg, AIMessage)]
            if ai_messages:
                final_response = ai_messages[-1].content
                print(f"\nğŸ¤– åŠ©æ‰‹: {final_response}")
            
            # æ˜¾ç¤ºæ‰§è¡Œç»Ÿè®¡
            print(f"\nğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
            print(f"   è¯†åˆ«æ„å›¾: {result.get('user_intent', 'æœªçŸ¥')}")
            print(f"   å·¥å…·è°ƒç”¨æ¬¡æ•°: {result.get('tool_calls_count', 0)}")
            print(f"   æœ€åå·¥å…·ç»“æœ: {result.get('last_tool_result', 'æ— ')[:50]}...")
            
        except Exception as e:
            print(f"âŒ å¤„ç†é”™è¯¯: {e}")

def demo_routing_logic():
    """æ¼”ç¤ºè·¯ç”±é€»è¾‘"""
    print("\nğŸ“ˆ è·¯ç”±é€»è¾‘æ¼”ç¤º:")
    print("-" * 30)
    
    test_inputs = [
        "è®¡ç®— 5+3",
        "ç¿»è¯‘ hello",
        "æœç´¢ AI",
        "ç°åœ¨å‡ ç‚¹",
        "ä½ å¥½å—"
    ]
    
    for input_text in test_inputs:
        intent = analyze_intent(input_text)
        route = "tool_calling" if intent in ["calculate", "translate", "search", "time"] else "chat"
        print(f"è¾“å…¥: '{input_text}' â†’ æ„å›¾: {intent} â†’ è·¯ç”±: {route}")

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ Challenge 2: æ¡ä»¶è·¯ç”±å’Œå·¥å…·è°ƒç”¨")
    
    # æ¼”ç¤ºè·¯ç”±é€»è¾‘
    demo_routing_logic()
    
    # è¿è¡Œæ™ºèƒ½åŠ©æ‰‹
    run_smart_assistant()
