"""
Challenge 4: æ£€æŸ¥ç‚¹å’ŒçŠ¶æ€æŒä¹…åŒ–

å­¦ä¹ ç›®æ ‡:
- æŒæ¡Checkpointeræœºåˆ¶
- å®ç°çŠ¶æ€æŒä¹…åŒ–
- å­¦ä¹ æ•…éšœæ¢å¤
- ç®¡ç†é•¿æœŸè®°å¿†

æ ¸å¿ƒæ¦‚å¿µ:
1. MemorySaver/SqliteSaver - æ£€æŸ¥ç‚¹å­˜å‚¨
2. æ£€æŸ¥ç‚¹é…ç½® - è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤
3. çŠ¶æ€æ¢å¤ - ä¸­æ–­åç»§ç»­æ‰§è¡Œ
4. æŒä¹…åŒ–ç­–ç•¥ - ä¸åŒå­˜å‚¨æ–¹æ¡ˆ
"""

import os
import sqlite3
import json
import time
from datetime import datetime
from typing import TypedDict, Annotated, Optional, cast, Any
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
# æ³¨æ„ï¼šå¦‚æœSqliteSaverä¸å¯ç”¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ
try:
    from langgraph.checkpoint.sqlite import SqliteSaver  # type: ignore
    SQLITE_AVAILABLE = True
except ImportError:
    SQLITE_AVAILABLE = False
    SqliteSaver = None  # type: ignore
    print("âš ï¸  SqliteSaver ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ MemorySaver æ›¿ä»£")
    
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage

# æ£€æŸ¥ç¯å¢ƒå˜é‡
if not os.getenv("OPENAI_API_KEY"):
    print("âš ï¸  è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    exit(1)

# 1. å®šä¹‰çŠ¶æ€ç»“æ„
class ConversationState(TypedDict):
    """æŒä¹…åŒ–å¯¹è¯çŠ¶æ€"""
    messages: Annotated[list, add_messages]
    user_profile: dict  # ç”¨æˆ·æ¡£æ¡ˆ
    conversation_history: list  # å¯¹è¯å†å²æ‘˜è¦
    preferences: dict  # ç”¨æˆ·åå¥½
    session_count: int  # ä¼šè¯è®¡æ•°
    last_checkpoint: str  # æœ€åæ£€æŸ¥ç‚¹æ—¶é—´

class TaskState(TypedDict):
    """é•¿æœŸä»»åŠ¡çŠ¶æ€"""
    task_id: str
    task_type: str  # research, analysis, writing
    current_step: int
    total_steps: int
    step_results: list
    status: str  # running, paused, completed, failed
    created_at: str
    updated_at: str

# 2. åˆå§‹åŒ–LLM
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

# 3. æ£€æŸ¥ç‚¹å­˜å‚¨å™¨
def create_memory_saver():
    """åˆ›å»ºå†…å­˜æ£€æŸ¥ç‚¹å­˜å‚¨å™¨"""
    return MemorySaver()

def create_sqlite_saver(db_path: str = "checkpoints.db"):
    """åˆ›å»ºSQLiteæ£€æŸ¥ç‚¹å­˜å‚¨å™¨"""
    if SQLITE_AVAILABLE and SqliteSaver is not None:
        return SqliteSaver.from_conn_string(f"sqlite:///{db_path}")
    else:
        print("âš ï¸  ä½¿ç”¨ MemorySaver æ›¿ä»£ SqliteSaver")
        return MemorySaver()

# 4. ç”¨æˆ·æ¡£æ¡ˆç®¡ç†èŠ‚ç‚¹
def profile_analysis_node(state: ConversationState) -> dict:
    """åˆ†æå’Œæ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ"""
    print("ğŸ‘¤ [æ¡£æ¡ˆåˆ†æ] æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ...")
    
    last_message = state["messages"][-1] if state["messages"] else None
    if not last_message:
        return {}
    
    user_input = last_message.content
    current_profile = state.get("user_profile", {})
    
    # ä½¿ç”¨LLMåˆ†æç”¨æˆ·ç‰¹å¾
    analysis_prompt = f"""åŸºäºç”¨æˆ·è¾“å…¥ï¼Œåˆ†æç”¨æˆ·ç‰¹å¾å¹¶æ›´æ–°æ¡£æ¡ˆ:

å½“å‰æ¡£æ¡ˆ: {json.dumps(current_profile, ensure_ascii=False, indent=2)}

ç”¨æˆ·è¾“å…¥: "{user_input}"

è¯·æ›´æ–°ä»¥ä¸‹å­—æ®µ(JSONæ ¼å¼):
- name: å§“å
- interests: å…´è¶£çˆ±å¥½åˆ—è¡¨
- communication_style: æ²Ÿé€šé£æ ¼
- expertise_level: ä¸“ä¸šæ°´å¹³
- preferred_topics: åå¥½è¯é¢˜
- last_interaction: æœ€åäº’åŠ¨æ—¶é—´

åªè¿”å›JSONæ ¼å¼çš„æ›´æ–°æ¡£æ¡ˆã€‚"""
    
    try:
        response = llm.invoke([{"role": "user", "content": analysis_prompt}])
        
        # å°è¯•è§£æLLMè¿”å›çš„JSON
        try:
            # ç¡®ä¿response.contentæ˜¯å­—ç¬¦ä¸²ç±»å‹
            content = response.content if isinstance(response.content, str) else str(response.content)
            updated_profile = json.loads(content)
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œä¿ç•™åŸæ¡£æ¡ˆå¹¶æ·»åŠ åŸºæœ¬ä¿¡æ¯
            updated_profile = current_profile.copy()
            updated_profile["last_interaction"] = datetime.now().isoformat()
            updated_profile["interaction_count"] = updated_profile.get("interaction_count", 0) + 1
        
        return {
            "user_profile": updated_profile,
            "last_checkpoint": datetime.now().isoformat()
        }
    
    except Exception as e:
        print(f"   æ¡£æ¡ˆåˆ†æå‡ºé”™: {e}")
        return {}

def conversation_node(state: ConversationState) -> dict:
    """ä¸»å¯¹è¯èŠ‚ç‚¹ - åŸºäºæ¡£æ¡ˆç”Ÿæˆä¸ªæ€§åŒ–å›å¤"""
    print("ğŸ’¬ [å¯¹è¯å¤„ç†] ç”Ÿæˆä¸ªæ€§åŒ–å›å¤...")
    
    user_profile = state.get("user_profile", {})
    preferences = state.get("preferences", {})
    conversation_history = state.get("conversation_history", [])
    
    # æ„å»ºä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡
    context = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œéœ€è¦åŸºäºç”¨æˆ·æ¡£æ¡ˆæä¾›ä¸ªæ€§åŒ–å›å¤ã€‚

ç”¨æˆ·æ¡£æ¡ˆ:
{json.dumps(user_profile, ensure_ascii=False, indent=2)}

ç”¨æˆ·åå¥½:
{json.dumps(preferences, ensure_ascii=False, indent=2)}

å¯¹è¯å†å²æ‘˜è¦:
{'; '.join(conversation_history[-3:]) if conversation_history else 'æ— '}

è¯·æ ¹æ®ç”¨æˆ·çš„ç‰¹ç‚¹å’Œåå¥½ï¼Œç”Ÿæˆè‡ªç„¶ã€ä¸ªæ€§åŒ–çš„å›å¤ã€‚"""
    
    # å‡†å¤‡å¯¹è¯æ¶ˆæ¯
    messages = [{"role": "system", "content": context}]
    
    # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²
    for msg in state["messages"][-5:]:  # æœ€è¿‘5æ¡æ¶ˆæ¯
        if isinstance(msg, HumanMessage):
            content = msg.content if isinstance(msg.content, str) else str(msg.content)
            messages.append({"role": "user", "content": content})
        elif isinstance(msg, AIMessage):
            content = msg.content if isinstance(msg.content, str) else str(msg.content)
            messages.append({"role": "assistant", "content": content})
    
    try:
        response = llm.invoke(messages)
        
        # æ›´æ–°å¯¹è¯å†å²æ‘˜è¦
        new_summary = f"ç”¨æˆ·è¯¢é—®: {state['messages'][-1].content[:50]}..."
        updated_history = conversation_history + [new_summary]
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†é•¿åº¦
        if len(updated_history) > 10:
            updated_history = updated_history[-10:]
        
        return {
            "messages": [AIMessage(content=response.content)],
            "conversation_history": updated_history,
            "session_count": state.get("session_count", 0) + 1,
            "last_checkpoint": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"   å¯¹è¯å¤„ç†å‡ºé”™: {e}")
        error_message = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•æ­£å¸¸å›å¤ã€‚è¯·ç¨åå†è¯•ã€‚"
        return {
            "messages": [AIMessage(content=error_message)],
            "last_checkpoint": datetime.now().isoformat()
        }

def memory_consolidation_node(state: ConversationState) -> dict:
    """è®°å¿†å·©å›ºèŠ‚ç‚¹ - æ•´ç†å’Œå‹ç¼©é•¿æœŸè®°å¿†"""
    print("ğŸ§  [è®°å¿†å·©å›º] æ•´ç†é•¿æœŸè®°å¿†...")
    
    # æ¯10æ¬¡äº¤äº’è¿›è¡Œä¸€æ¬¡è®°å¿†å·©å›º
    session_count = state.get("session_count", 0)
    if session_count % 10 != 0:
        return {}
    
    conversation_history = state.get("conversation_history", [])
    user_profile = state.get("user_profile", {})
    
    if len(conversation_history) < 5:
        return {}
    
    consolidation_prompt = f"""æ•´ç†ä»¥ä¸‹å¯¹è¯å†å²ï¼Œç”Ÿæˆç®€æ´çš„è®°å¿†æ‘˜è¦:

ç”¨æˆ·æ¡£æ¡ˆ: {json.dumps(user_profile, ensure_ascii=False)}

å¯¹è¯å†å²:
{chr(10).join(conversation_history)}

è¯·ç”Ÿæˆ:
1. å…³é”®å¯¹è¯ä¸»é¢˜æ‘˜è¦
2. ç”¨æˆ·åå¥½æ›´æ–°å»ºè®®
3. é‡è¦ä¿¡æ¯æå–

è¿”å›JSONæ ¼å¼:
{{
    "key_topics": ["ä¸»é¢˜1", "ä¸»é¢˜2"],
    "preference_updates": {{"åå¥½1": "å€¼1"}},
    "important_facts": ["äº‹å®1", "äº‹å®2"]
}}"""
    
    try:
        response = llm.invoke([{"role": "user", "content": consolidation_prompt}])
        # ç¡®ä¿contentæ˜¯å­—ç¬¦ä¸²ç±»å‹
        content = response.content if isinstance(response.content, str) else str(response.content)
        consolidation_result = json.loads(content)
        
        # æ›´æ–°åå¥½
        current_preferences = state.get("preferences", {})
        new_preferences = {
            **current_preferences,
            **consolidation_result.get("preference_updates", {})
        }
        
        # å‹ç¼©å¯¹è¯å†å²
        compressed_history = [
            f"ä¸»é¢˜æ‘˜è¦: {', '.join(consolidation_result.get('key_topics', []))}",
            f"é‡è¦äº‹å®: {', '.join(consolidation_result.get('important_facts', []))}"
        ]
        
        print("   è®°å¿†å·©å›ºå®Œæˆ")
        return {
            "conversation_history": compressed_history,
            "preferences": new_preferences,
            "last_checkpoint": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"   è®°å¿†å·©å›ºå‡ºé”™: {e}")
        return {}

# 5. é•¿æœŸä»»åŠ¡èŠ‚ç‚¹
def task_execution_node(state: TaskState) -> dict:
    """ä»»åŠ¡æ‰§è¡ŒèŠ‚ç‚¹ - å¯ä¸­æ–­å’Œæ¢å¤çš„é•¿æœŸä»»åŠ¡"""
    print(f"ğŸ”„ [ä»»åŠ¡æ‰§è¡Œ] æ‰§è¡Œæ­¥éª¤ {state['current_step']}/{state['total_steps']}")
    
    current_step = state["current_step"]
    task_type = state["task_type"]
    
    # æ¨¡æ‹Ÿä¸åŒç±»å‹ä»»åŠ¡çš„æ­¥éª¤
    step_prompts = {
        "research": [
            "æ”¶é›†ç›¸å…³èµ„æ–™å’Œæ•°æ®æº",
            "åˆ†æç°æœ‰ç ”ç©¶å’Œæ–‡çŒ®",
            "æ€»ç»“å…³é”®å‘ç°å’Œè§‚ç‚¹",
            "å½¢æˆç ”ç©¶ç»“è®ºå’Œå»ºè®®"
        ],
        "analysis": [
            "æ•°æ®æ”¶é›†å’Œæ¸…ç†",
            "æ¢ç´¢æ€§æ•°æ®åˆ†æ",
            "æ·±åº¦ç»Ÿè®¡åˆ†æ",
            "ç»“æœè§£é‡Šå’Œå¯è§†åŒ–"
        ],
        "writing": [
            "ç¡®å®šæ–‡ç« ç»“æ„å’Œå¤§çº²",
            "æ’°å†™ç¬¬ä¸€ç¨¿å†…å®¹",
            "ä¿®è®¢å’Œå®Œå–„å†…å®¹",
            "æœ€ç»ˆæ ¡å¯¹å’Œæ ¼å¼åŒ–"
        ]
    }
    
    if task_type not in step_prompts:
        return {"status": "failed", "updated_at": datetime.now().isoformat()}
    
    steps = step_prompts[task_type]
    if current_step > len(steps):
        return {"status": "completed", "updated_at": datetime.now().isoformat()}
    
    current_task = steps[current_step - 1]
    print(f"   æ‰§è¡Œ: {current_task}")
    
    # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œæ—¶é—´
    time.sleep(1)
    
    # ç”Ÿæˆæ­¥éª¤ç»“æœ
    step_result = f"æ­¥éª¤{current_step}å®Œæˆ: {current_task} - {datetime.now().strftime('%H:%M:%S')}"
    
    step_results = state.get("step_results", [])
    step_results.append(step_result)
    
    next_step = current_step + 1
    status = "completed" if next_step > len(steps) else "running"
    
    return {
        "current_step": next_step,
        "step_results": step_results,
        "status": status,
        "updated_at": datetime.now().isoformat()
    }

# 6. æ„å»ºæŒä¹…åŒ–å¯¹è¯ç³»ç»Ÿ
def create_persistent_chat_system(checkpointer):
    """åˆ›å»ºå¸¦æ£€æŸ¥ç‚¹çš„å¯¹è¯ç³»ç»Ÿ"""
    
    workflow = StateGraph(ConversationState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("profile_analysis", profile_analysis_node)
    workflow.add_node("conversation", conversation_node)
    workflow.add_node("memory_consolidation", memory_consolidation_node)
    
    # è®¾ç½®æµç¨‹
    workflow.add_edge(START, "profile_analysis")
    workflow.add_edge("profile_analysis", "conversation")
    workflow.add_edge("conversation", "memory_consolidation")
    workflow.add_edge("memory_consolidation", END)
    
    # ç¼–è¯‘æ—¶æ·»åŠ æ£€æŸ¥ç‚¹
    return workflow.compile(checkpointer=checkpointer)

def create_task_system(checkpointer):
    """åˆ›å»ºé•¿æœŸä»»åŠ¡ç³»ç»Ÿ"""
    
    workflow = StateGraph(TaskState)
    workflow.add_node("execute_step", task_execution_node)
    
    # æ¡ä»¶å¾ªç¯ï¼šç»§ç»­æˆ–å®Œæˆ
    def should_continue(state: TaskState) -> str:
        status = state.get("status", "running")
        return "continue" if status == "running" else "end"
    
    workflow.add_edge(START, "execute_step")
    workflow.add_conditional_edges(
        "execute_step",
        should_continue,
        {
            "continue": "execute_step",
            "end": END
        }
    )
    
    return workflow.compile(checkpointer=checkpointer)

# 7. æ¼”ç¤ºå‡½æ•°
def demo_persistent_chat():
    """æ¼”ç¤ºæŒä¹…åŒ–å¯¹è¯"""
    print("=" * 60)
    print("ğŸ’¬ æŒä¹…åŒ–å¯¹è¯ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    print("ç‰¹æ€§:")
    print("- ç”¨æˆ·æ¡£æ¡ˆæŒä¹…åŒ–")
    print("- å¯¹è¯å†å²è®°å¿†")
    print("- åå¥½å­¦ä¹ å’Œæ›´æ–°")
    print("- ä¼šè¯ä¸­æ–­å’Œæ¢å¤")
    print("\nè¾“å…¥ 'save' æŸ¥çœ‹æ£€æŸ¥ç‚¹ï¼Œ'load' æ¢å¤ï¼Œ'quit' é€€å‡º")
    print("-" * 60)
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹å­˜å‚¨
    memory_saver = create_memory_saver()
    
    # åˆ›å»ºå¯¹è¯ç³»ç»Ÿ
    chat_system = create_persistent_chat_system(memory_saver)
    
    # çº¿ç¨‹IDç”¨äºæ ‡è¯†ä¼šè¯
    thread_id = "demo_session_" + datetime.now().strftime("%Y%m%d_%H%M%S")
    config = {"configurable": {"thread_id": thread_id}}
    
    # åˆå§‹åŒ–çŠ¶æ€
    initial_state = {
        "messages": [],
        "user_profile": {},
        "conversation_history": [],
        "preferences": {},
        "session_count": 0,
        "last_checkpoint": datetime.now().isoformat()
    }
    
    print(f"ğŸ†” ä¼šè¯ID: {thread_id}")
    
    while True:
        user_input = input("\nğŸ‘¤ ä½ : ").strip()
        
        if user_input.lower() == 'quit':
            print("ğŸ‘‹ ä¼šè¯ç»“æŸ!")
            break
        elif user_input.lower() == 'save':
            # æ˜¾ç¤ºå½“å‰æ£€æŸ¥ç‚¹ä¿¡æ¯
            try:
                config_typed = cast(Any, config)
                checkpoint = memory_saver.get(config_typed)
                if checkpoint:
                    print("ğŸ’¾ å½“å‰æ£€æŸ¥ç‚¹:")
                    state = checkpoint.get("channel_values", {})
                    print(f"   ä¼šè¯è®¡æ•°: {state.get('session_count', 0)}")
                    print(f"   ç”¨æˆ·æ¡£æ¡ˆ: {json.dumps(state.get('user_profile', {}), ensure_ascii=False, indent=2)}")
                    print(f"   æœ€åæ›´æ–°: {state.get('last_checkpoint', 'N/A')}")
                else:
                    print("ğŸ“ æš‚æ— æ£€æŸ¥ç‚¹")
            except Exception as e:
                print(f"âŒ æ£€æŸ¥ç‚¹æŸ¥çœ‹å¤±è´¥: {e}")
            continue
        elif user_input.lower() == 'load':
            print("ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤ä¼šè¯...")
            continue
        elif not user_input:
            continue
        
        try:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            current_state = cast(ConversationState, {
                **initial_state,
                "messages": [HumanMessage(content=user_input)]
            })
            
            print("ğŸ”„ å¤„ç†ä¸­...")
            
            # æ‰§è¡Œå¯¹è¯æµç¨‹
            config_typed = cast(Any, config)
            result = chat_system.invoke(current_state, config_typed)
            
            # è·å–AIå›å¤
            ai_messages = [msg for msg in result["messages"] if isinstance(msg, AIMessage)]
            if ai_messages:
                print(f"\nğŸ¤– åŠ©æ‰‹: {ai_messages[-1].content}")
            
            # æ˜¾ç¤ºçŠ¶æ€æ›´æ–°
            print(f"\nğŸ“Š çŠ¶æ€æ›´æ–°:")
            print(f"   ä¼šè¯è®¡æ•°: {result.get('session_count', 0)}")
            if result.get('user_profile'):
                print(f"   æ¡£æ¡ˆæ›´æ–°: âœ…")
            if result.get('conversation_history'):
                print(f"   å†å²è®°å½•: {len(result.get('conversation_history', []))} æ¡")
            
            # æ›´æ–°åˆå§‹çŠ¶æ€ç”¨äºä¸‹æ¬¡å¯¹è¯
            initial_state = result
            
        except Exception as e:
            print(f"âŒ å¤„ç†é”™è¯¯: {e}")

def demo_task_recovery():
    """æ¼”ç¤ºä»»åŠ¡æ¢å¤åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ”„ é•¿æœŸä»»åŠ¡æ¢å¤æ¼”ç¤º")
    print("="*60)
    
    # åˆ›å»ºSQLiteæ£€æŸ¥ç‚¹å­˜å‚¨
    sqlite_saver = create_sqlite_saver("demo_tasks.db")
    task_system = create_task_system(sqlite_saver)
    
    # ä»»åŠ¡é…ç½®
    task_id = "demo_task_" + datetime.now().strftime("%Y%m%d_%H%M%S")
    config = {"configurable": {"thread_id": task_id}}
    
    print("é€‰æ‹©ä»»åŠ¡ç±»å‹:")
    print("1. research - ç ”ç©¶ä»»åŠ¡")
    print("2. analysis - åˆ†æä»»åŠ¡") 
    print("3. writing - å†™ä½œä»»åŠ¡")
    
    choice = input("è¯·é€‰æ‹© (1-3): ").strip()
    task_types = {"1": "research", "2": "analysis", "3": "writing"}
    task_type = task_types.get(choice, "research")
    
    # åˆå§‹ä»»åŠ¡çŠ¶æ€
    initial_task: TaskState = {
        "task_id": task_id,
        "task_type": task_type,
        "current_step": 1,
        "total_steps": 4,
        "step_results": [],
        "status": "running",
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat()
    }
    
    print(f"\nğŸš€ å¯åŠ¨ {task_type} ä»»åŠ¡: {task_id}")
    print("æŒ‰ Ctrl+C å¯ä»¥ä¸­æ–­ä»»åŠ¡ï¼Œç¨åæ¢å¤")
    print("-" * 40)
    
    try:
        # æ‰§è¡Œä»»åŠ¡
        config_typed = cast(Any, config)
        result = task_system.invoke(initial_task, config_typed)
        
        print(f"\nâœ… ä»»åŠ¡å®Œæˆ!")
        print(f"çŠ¶æ€: {result.get('status')}")
        print(f"å®Œæˆæ­¥éª¤: {result.get('current_step', 1) - 1}/{result.get('total_steps', 4)}")
        
        print("\nğŸ“‹ æ‰§è¡Œè®°å½•:")
        for step_result in result.get("step_results", []):
            print(f"   {step_result}")
            
    except KeyboardInterrupt:
        print(f"\nâ¸ï¸  ä»»åŠ¡å·²ä¸­æ–­ï¼Œä¿å­˜åœ¨æ£€æŸ¥ç‚¹: {task_id}")
        print("å¯ä»¥ç¨åä½¿ç”¨ç›¸åŒçš„thread_idæ¢å¤ä»»åŠ¡")
        
        # æ˜¾ç¤ºå¦‚ä½•æ¢å¤
        print("\næ¢å¤å‘½ä»¤ç¤ºä¾‹:")
        print(f"task_system.invoke(None, {{'configurable': {{'thread_id': '{task_id}'}}}})")

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ Challenge 4: æ£€æŸ¥ç‚¹å’ŒçŠ¶æ€æŒä¹…åŒ–")
    
    print("\né€‰æ‹©æ¼”ç¤º:")
    print("1. æŒä¹…åŒ–å¯¹è¯ç³»ç»Ÿ")
    print("2. é•¿æœŸä»»åŠ¡æ¢å¤")
    
    choice = input("è¯·é€‰æ‹© (1-2): ").strip()
    
    if choice == "2":
        demo_task_recovery()
    else:
        demo_persistent_chat()
