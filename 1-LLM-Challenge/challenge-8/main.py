"""
Challenge 8: è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆSTTï¼‰â€” ä½¿ç”¨ OpenAI whisper-1 è½¬å†™éŸ³é¢‘

ç”¨æ³•ï¼ˆPowerShellï¼‰ï¼š
	python main.py -f audio.mp3 --language zh

å‚æ•°ï¼š
- -f / --file éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ mp3/mp4/mpeg/mpga/m4a/wav/webmï¼‰
- --language å¯é€‰è¯­è¨€æç¤ºï¼ˆå¦‚ zh/enï¼‰

ç¯å¢ƒå˜é‡ï¼š
- OPENAI_API_KEYï¼ˆå¿…éœ€ï¼‰
- OPENAI_BASE_URLï¼ˆå¯é€‰ï¼Œè‡ªå®šä¹‰ç½‘å…³åœ°å€ï¼‰
- OPENAI_TRANSCRIBE_MODELï¼ˆå¯é€‰ï¼Œé»˜è®¤ whisper-1ï¼‰
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Optional
from pydantic import BaseModel, Field
from langchain_core.tools import tool

try:
	from openai import OpenAI
except Exception as e:  # pragma: no cover - helpful message if dependency missing
	print("[é”™è¯¯] ç¼ºå°‘ä¾èµ– 'openai'ã€‚è¯·å°†å…¶åŠ å…¥ requirements å¹¶å®‰è£…ã€‚", file=sys.stderr)
	raise


SUPPORTED_AUDIO_EXTS = {".mp3", ".mp4", ".mpeg", ".mpga", ".m4a", ".wav", ".webm"}

def _extract_text(resp) -> str:
	"""å°½åŠ›ä» SDK å“åº”å¯¹è±¡ä¸­æå–è½¬å†™æ–‡æœ¬ã€‚"""
	# OpenAI SDK v1.x é€šå¸¸è¿”å›åŒ…å« `.text` å­—æ®µçš„å¯¹è±¡
	text = getattr(resp, "text", None)
	if isinstance(text, str) and text.strip():
		return text
	# æŸäº›å®ç°å¯èƒ½è¿”å› dict
	if isinstance(resp, dict) and isinstance(resp.get("text"), str):
		return resp["text"]
	return str(resp)


def ensure_api_key() -> None:
	if os.getenv("OPENAI_API_KEY"):
		return
	print("âŒ æœªæ£€æµ‹åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ã€‚", file=sys.stderr)
	print("ğŸ’¡ åœ¨ PowerShell ä¸‹å¯æ‰§è¡Œ: $env:OPENAI_API_KEY='your-openai-key'", file=sys.stderr)
	sys.exit(2)


def transcribe(file_path: str, model: Optional[str] = None, language: Optional[str] = None) -> str:
	"""
	ä½¿ç”¨ OpenAI whisper-1 å°†éŸ³é¢‘æ–‡ä»¶è½¬å†™ä¸ºæ–‡æœ¬ã€‚

	å‚æ•°ï¼š
		file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ã€‚
		model: æ¨¡å‹åç§°ï¼›ä¸æŒ‡å®šæ—¶ä½¿ç”¨ç¯å¢ƒå˜é‡ OPENAI_TRANSCRIBE_MODEL æˆ– 'whisper-1'ã€‚
		language: å¯é€‰è¯­è¨€æç¤ºï¼ˆBCP-47ï¼‰ï¼Œä¾‹å¦‚ 'zh'ã€'en'ã€‚

	è¿”å›ï¼š
		è½¬å†™æ–‡æœ¬ã€‚
	"""
	model_name = model or os.getenv("OPENAI_TRANSCRIBE_MODEL", "whisper-1")
	# å…è®¸é€šè¿‡ OPENAI_BASE_URL æŒ‡å®šè‡ªå®šä¹‰ç½‘å…³
	client_kwargs = {}
	base_url = os.getenv("OPENAI_API_BASE")
	if base_url:
		client_kwargs["base_url"] = base_url
	client = OpenAI(**client_kwargs)
	with open(file_path, "rb") as f:
		if language:
			resp = client.audio.transcriptions.create(  # type: ignore[attr-defined]
				model=model_name,
				file=f,
				language=language,
			)
		else:
			resp = client.audio.transcriptions.create(  # type: ignore[attr-defined]
				model=model_name,
				file=f,
			)
	return _extract_text(resp)


# LangChain v0.3: å®šä¹‰ä¸€ä¸ªå¯å¤ç”¨çš„è½¬å†™å·¥å…·
class TranscribeToolInput(BaseModel):
	file: str = Field(..., description="éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒ mp3/mp4/mpeg/mpga/m4a/wav/webm")
	language: Optional[str] = Field(None, description="å¯é€‰è¯­è¨€æç¤ºï¼Œå¦‚ 'zh' æˆ– 'en'")
	model: Optional[str] = Field(None, description="å¯é€‰æ¨¡å‹åï¼Œé»˜è®¤ whisper-1")


@tool("openai_transcribe", args_schema=TranscribeToolInput)
def openai_transcribe(file: str, language: Optional[str] = None, model: Optional[str] = None) -> str:
	"""ä½¿ç”¨ OpenAI whisper-1 å°†éŸ³é¢‘è½¬å†™ä¸ºæ–‡æœ¬å¹¶è¿”å›ç»“æœå­—ç¬¦ä¸²ã€‚"""
	p = Path(file)
	if not p.exists() or not p.is_file():
		raise FileNotFoundError(f"æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {p}")
	# è½»é‡æ ¼å¼æ ¡éªŒï¼ˆä»…å‘Šè­¦ä¸æ‹¦æˆªï¼‰åœ¨ CLI ä¸­æ‰§è¡Œï¼›å·¥å…·ä¸­ç›´æ¥æ‰§è¡Œ
	return transcribe(str(p), model=model, language=language)


def main(argv: Optional[list[str]] = None) -> int:
	ensure_api_key()
	parser = argparse.ArgumentParser(description="ä½¿ç”¨ OpenAI whisper-1 å°†éŸ³é¢‘è½¬å†™ä¸ºæ–‡æœ¬ï¼ˆLangChain å·¥å…·é£æ ¼ï¼‰")
	parser.add_argument("-f", "--file", required=True, help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (mp3/mp4/mpeg/mpga/m4a/wav/webm)")
	parser.add_argument("--language", default=None, help="å¯é€‰è¯­è¨€æç¤ºï¼Œå¦‚ 'zh' æˆ– 'en'")
	args = parser.parse_args(argv)

	audio_path = Path(args.file)
	if not audio_path.exists() or not audio_path.is_file():
		print(f"[é”™è¯¯] æœªæ‰¾åˆ°æ–‡ä»¶: {audio_path}", file=sys.stderr)
		return 2

	ext = audio_path.suffix.lower()
	if ext not in SUPPORTED_AUDIO_EXTS:
		print(f"[è­¦å‘Š] æœªè¯†åˆ«çš„æ–‡ä»¶æ‰©å±•å '{ext}'ï¼Œå°†ç»§ç»­å°è¯•è½¬å†™â€¦", file=sys.stderr)

	try:
		text = openai_transcribe.invoke({
			"file": str(audio_path),
			"language": args.language,
		})
	except Exception as e:
		print(f"[é”™è¯¯] è½¬å†™å¤±è´¥: {e}", file=sys.stderr)
		return 1

	print(text)
	return 0


if __name__ == "__main__":
	raise SystemExit(main())

