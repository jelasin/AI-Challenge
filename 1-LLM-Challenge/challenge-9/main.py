r"""
Challenge 9: è¯­éŸ³å®æ—¶äº¤äº’ï¼ˆRealtimeï¼‰â€” ä½¿ç”¨ gpt-4o-realtime-preview

è¯´æ˜ï¼š
- æœ¬è„šæœ¬é€šè¿‡ WebSocket å¯¹æ¥ OpenAI Realtime APIï¼Œé‡‡é›†éº¦å…‹é£éŸ³é¢‘å¹¶æ’­æ”¾æ¨¡å‹çš„è¯­éŸ³å›å¤ã€‚
- é»˜è®¤ä½¿ç”¨â€œæŒ‰é”®è¯´è¯â€(PTT)æ¨¡å¼ï¼šæŒ‰å›è½¦é”®æäº¤å½“å‰å·²å½•åˆ¶çš„è¯­éŸ³ç‰‡æ®µï¼Œæ¨¡å‹è¿”å›è¯­éŸ³å¹¶æ’­æ”¾ã€‚
- å¯é€‰â€œæœåŠ¡ç«¯ VADâ€æ¨¡å¼ï¼ˆ--mode vadï¼‰ï¼Œç”±æœåŠ¡ç«¯è¿›è¡Œè¯­éŸ³ç«¯ç‚¹æ£€æµ‹ï¼ˆå®éªŒæ€§ï¼Œå¯èƒ½ä¾èµ–ç½‘å…³æ”¯æŒï¼‰ã€‚

ç”¨æ³•ï¼ˆPowerShellï¼‰ï¼š
  python .\main.py --list-devices               # åˆ—å‡ºéŸ³é¢‘è®¾å¤‡
  python .\main.py --input-device 1 --output-device 3  # é€‰æ‹©è®¾å¤‡ç´¢å¼•
  python .\main.py --mode ptt                    # é»˜è®¤æŒ‰é”®è¯´è¯æ¨¡å¼
  python .\main.py --mode vad                    # æœåŠ¡ç«¯ VAD å®éªŒæ¨¡å¼

ç¯å¢ƒå˜é‡ï¼š
- OPENAI_API_KEYï¼ˆå¿…éœ€ï¼‰
- OPENAI_BASE_URLï¼ˆå¯é€‰ï¼Œè‡ªå®šä¹‰ç½‘å…³ï¼›è‹¥æ”¯æŒ Realtimeï¼Œå°†è‡ªåŠ¨è½¬æ¢ä¸º wss ç«¯ç‚¹ï¼‰

ä¾èµ–ï¼š
- websockets, sounddevice, numpy, openai
"""

from __future__ import annotations

import asyncio
import base64
import json
import os
import signal
import sys
import threading
import time
from dataclasses import dataclass
from queue import Queue
from typing import Optional

import numpy as np
import sounddevice as sd

try:
    import websockets
except Exception:
    print("ç¼ºå°‘ä¾èµ– websocketsï¼Œè¯·å…ˆå®‰è£…ï¼špip install websockets", file=sys.stderr)
    raise


DEFAULT_MODEL = os.getenv("OPENAI_REALTIME_MODEL", "gpt-4o-realtime-preview")
SAMPLE_RATE = 24000  # ä¸ Realtime è¯­éŸ³é»˜è®¤é‡‡æ ·ç‡å¯¹é½
CHANNELS = 1
DTYPE = "int16"  # PCM16


def ensure_api_key() -> None:
    if os.getenv("OPENAI_API_KEY"):
        return
    print("âŒ æœªæ£€æµ‹åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ã€‚", file=sys.stderr)
    print("ğŸ’¡ åœ¨ PowerShell è®¾ç½®: $env:OPENAI_API_KEY='your-key'", file=sys.stderr)
    sys.exit(2)


def list_devices_and_exit() -> None:
    print("å¯ç”¨éŸ³é¢‘è®¾å¤‡ï¼š")
    print(sd.query_devices())
    sys.exit(0)


def make_ws_uri(model: str) -> str:
    base = os.getenv("OPENAI_BASE_URL")
    if base:
        # å°† http(s) è½¬ä¸º ws(s) å¹¶æ‹¼æ¥ realtime è·¯å¾„
        if base.startswith("https://"):
            ws_base = "wss://" + base[len("https://"):]
        elif base.startswith("http://"):
            ws_base = "ws://" + base[len("http://"):]
        else:
            ws_base = base  # å·²æ˜¯ ws(s) å½¢å¼æˆ–ç½‘å…³è‡ªå®šä¹‰
        if not ws_base.endswith("/"):
            ws_base += "/"
        return f"{ws_base}v1/realtime?model={model}"
    # OpenAI å…¬ç½‘é»˜è®¤åœ°å€
    return f"wss://api.openai.com/v1/realtime?model={model}"


@dataclass
class AudioConfig:
    input_device: Optional[int] = None
    output_device: Optional[int] = None
    sample_rate: int = SAMPLE_RATE
    channels: int = CHANNELS
    dtype: str = DTYPE


class MicStreamer:
    """éº¦å…‹é£é‡‡é›†çº¿ç¨‹ï¼Œå°† PCM16 åŸå§‹å­—èŠ‚æ”¾å…¥é˜Ÿåˆ—ã€‚"""

    def __init__(self, cfg: AudioConfig, queue: Queue[bytes]):
        self.cfg = cfg
        self.queue = queue
        self.stream: Optional[sd.InputStream] = None
        self._stop = threading.Event()

    def _callback(self, indata, frames, time_info, status):  # noqa: ANN001
        if status:
            # è®°å½•æ½œåœ¨çš„æº¢å‡º/æ¬ è½½
            print(f"[mic] status: {status}")
        data_bytes = indata.astype(self.cfg.dtype).tobytes()
        self.queue.put(data_bytes)

    def start(self):
        self.stream = sd.InputStream(
            samplerate=self.cfg.sample_rate,
            channels=self.cfg.channels,
            dtype=self.cfg.dtype,
            callback=self._callback,
            device=self.cfg.input_device,
            blocksize=0,
        )
        self.stream.start()

    def stop(self):
        self._stop.set()
        if self.stream is not None:
            try:
                self.stream.stop()
            except Exception:
                pass
            try:
                self.stream.close()
            except Exception:
                pass


class Speaker:
    """æ‰¬å£°å™¨æ’­æ”¾å™¨ï¼Œå‘è¾“å‡ºè®¾å¤‡å†™å…¥ PCM16 æ•°æ®ã€‚"""

    def __init__(self, cfg: AudioConfig):
        self.cfg = cfg
        self.stream: Optional[sd.OutputStream] = None

    def start(self):
        self.stream = sd.OutputStream(
            samplerate=self.cfg.sample_rate,
            channels=self.cfg.channels,
            dtype=self.cfg.dtype,
            device=self.cfg.output_device,
            blocksize=0,
        )
        self.stream.start()

    def write(self, pcm_bytes: bytes):
        if not self.stream:
            return
        # å°† bytes -> int16 -> float32 å¹¶å†™å…¥ï¼ˆsounddevice å…è®¸ç›´æ¥ int16ï¼‰
        try:
            arr = np.frombuffer(pcm_bytes, dtype=np.int16)
            self.stream.write(arr)
        except Exception as e:
            print(f"[spk] å†™å…¥å¤±è´¥: {e}")

    def stop(self):
        if self.stream is not None:
            try:
                self.stream.stop()
            except Exception:
                pass
            try:
                self.stream.close()
            except Exception:
                pass


async def ws_sender(ws, mic_q: Queue[bytes], mode: str):
    """å°†éº¦å…‹é£æ•°æ®æŒç»­å‘é€åˆ° Realtimeï¼šinput_audio_buffer.appendã€‚

    åœ¨ ptt æ¨¡å¼ä¸‹ï¼Œå›è½¦åæäº¤ç¼“å†²å¹¶è¯·æ±‚ç”Ÿæˆä¸€æ¬¡å“åº”ã€‚
    åœ¨ vad æ¨¡å¼ä¸‹ï¼Œä»…æŒç»­ appendï¼Œç”±æœåŠ¡ç«¯è‡ªåŠ¨è¿›è¡Œç«¯ç‚¹æ£€æµ‹ä¸å“åº”ã€‚
    """
    loop = asyncio.get_event_loop()

    async def send_json(payload: dict):
        await ws.send(json.dumps(payload))

    print("ğŸ¤ å¼€å§‹é‡‡é›†éº¦å…‹é£ã€‚PTT æ¨¡å¼ä¸‹æŒ‰å›è½¦æäº¤ä¸€æ¬¡è¯­éŸ³å¹¶è¯·æ±‚å›å¤ã€‚Ctrl+C ç»“æŸã€‚")

    # åå°çº¿ç¨‹ç›‘å¬é”®ç›˜ï¼ˆä»… ptt æ¨¡å¼ï¼‰
    commit_requested = False

    def key_listener():
        nonlocal commit_requested
        try:
            while True:
                _ = sys.stdin.readline()
                commit_requested = True
        except Exception:
            pass

    if mode == "ptt":
        t = threading.Thread(target=key_listener, daemon=True)
        t.start()

    last_commit = time.time()
    while True:
        try:
            chunk = await loop.run_in_executor(None, lambda: mic_q.get(timeout=0.2))
        except Exception:
            chunk = None

        if chunk:
            await send_json({
                "type": "input_audio_buffer.append",
                "audio": base64.b64encode(chunk).decode("utf-8"),
            })

        if mode == "ptt" and commit_requested:
            # æäº¤å½“å‰ç¼“å†²å¹¶åˆ›å»ºä¸€æ¬¡å“åº”ï¼ˆè¯­éŸ³è¾“å‡ºï¼‰
            await send_json({"type": "input_audio_buffer.commit"})
            await send_json({
                "type": "response.create",
                "response": {
                    "modalities": ["audio"],
                    "instructions": "è¯·ç®€è¦å›ç­”å¹¶ç”¨ä¸­æ–‡è¯­éŸ³å›å¤ã€‚",
                    "audio": {"voice": "alloy", "format": "pcm16"},
                },
            })
            commit_requested = False
            last_commit = time.time()

        # åœ¨ vad æ¨¡å¼ä¸‹ï¼Œå¯é€‰æ‹©å®šæ—¶ commit ä½œä¸ºå…¼å®¹ï¼ˆéƒ¨åˆ†æœåŠ¡ç«¯å¯èƒ½ä»éœ€ commitï¼‰
        if mode == "vad" and time.time() - last_commit > 4.0:
            await send_json({"type": "input_audio_buffer.commit"})
            last_commit = time.time()


async def ws_receiver(ws, speaker: Speaker):
    """æ¥æ”¶æœåŠ¡ç«¯äº‹ä»¶ï¼Œæå–éŸ³é¢‘ delta å¹¶æ’­æ”¾ã€‚"""
    async for message in ws:
        try:
            data = json.loads(message)
        except Exception:
            continue

        evt_type = data.get("type")
        # å¸¸è§äº‹ä»¶ï¼šresponse.output_audio.delta / response.audio.delta
        if isinstance(evt_type, str) and "audio" in evt_type and "delta" in evt_type:
            # å–éŸ³é¢‘å­—æ®µï¼ˆä¸åŒå®ç°å¯èƒ½ä½¿ç”¨ audio / delta / chunk ç­‰å‘½åï¼‰
            audio_b64 = (
                data.get("audio")
                or data.get("delta")
                or (data.get("output_audio") or {}).get("delta")
            )
            if isinstance(audio_b64, str):
                try:
                    pcm = base64.b64decode(audio_b64)
                    speaker.write(pcm)
                except Exception as e:
                    print(f"[recv] éŸ³é¢‘è§£ç å¤±è´¥: {e}")
        elif evt_type == "error":
            print(f"[error] {data}")
        elif evt_type and evt_type.endswith("completed"):
            # ä¸€æ¬¡å›å¤å®Œæˆ
            pass


async def run(model: str, input_device: Optional[int], output_device: Optional[int], mode: str):
    ensure_api_key()

    cfg = AudioConfig(input_device=input_device, output_device=output_device)
    mic_q: Queue[bytes] = Queue(maxsize=64)

    mic = MicStreamer(cfg, mic_q)
    spk = Speaker(cfg)

    # å¯åŠ¨æœ¬åœ°éŸ³é¢‘ I/O
    spk.start()
    mic.start()

    uri = make_ws_uri(model)
    headers = {
        "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
        "OpenAI-Beta": "realtime=v1",
    }

    async with websockets.connect(uri, extra_headers=headers, max_size=16 * 1024 * 1024) as ws:
        # é…ç½®ä¼šè¯ï¼šæŒ‡å®šè¾“å…¥/è¾“å‡ºéŸ³é¢‘æ ¼å¼ä¸ VAD
        session_update = {
            "type": "session.update",
            "session": {
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "voice": "alloy",
            },
        }
        if mode == "vad":
            session_update["session"]["turn_detection"] = {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 600,
            }

        await ws.send(json.dumps(session_update))

        sender_task = asyncio.create_task(ws_sender(ws, mic_q, mode))
        receiver_task = asyncio.create_task(ws_receiver(ws, spk))

        # ç­‰å¾…ä»»ä¸€ä»»åŠ¡ç»“æŸï¼ˆæˆ– Ctrl+Cï¼‰
        done, pending = await asyncio.wait(
            {sender_task, receiver_task}, return_when=asyncio.FIRST_COMPLETED
        )
        for task in pending:
            task.cancel()

    # å…³é—­éŸ³é¢‘
    mic.stop()
    spk.stop()


def parse_args(argv: list[str]):
    import argparse

    p = argparse.ArgumentParser(description="gpt-4o-realtime-preview è¯­éŸ³äº¤äº’")
    p.add_argument("--model", default=DEFAULT_MODEL, help="Realtime æ¨¡å‹å")
    p.add_argument("--list-devices", action="store_true", help="åˆ—å‡ºå¯ç”¨éŸ³é¢‘è®¾å¤‡å¹¶é€€å‡º")
    p.add_argument("--input-device", type=int, default=None, help="è¾“å…¥è®¾å¤‡ç´¢å¼•")
    p.add_argument("--output-device", type=int, default=None, help="è¾“å‡ºè®¾å¤‡ç´¢å¼•")
    p.add_argument("--mode", choices=["ptt", "vad"], default="ptt", help="äº¤äº’æ¨¡å¼ï¼šptt=æŒ‰é”®è¯´è¯, vad=æœåŠ¡ç«¯VAD(å®éªŒ)")
    return p.parse_args(argv)


def main(argv: Optional[list[str]] = None) -> int:
    args = parse_args(argv or sys.argv[1:])
    if args.list_devices:
        list_devices_and_exit()

    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    # ä¼˜é›…é€€å‡º
    for sig in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(sig, loop.stop)
        except NotImplementedError:
            # Windows ä¸‹å¯èƒ½ä¸æ”¯æŒ
            pass

    try:
        loop.run_until_complete(run(
            model=args.model,
            input_device=args.input_device,
            output_device=args.output_device,
            mode=args.mode,
        ))
        return 0
    except Exception as e:
        print(f"âŒ è¿è¡Œå¤±è´¥: {e}", file=sys.stderr)
        return 1
    finally:
        try:
            loop.close()
        except Exception:
            pass


if __name__ == "__main__":
    sys.exit(main())
